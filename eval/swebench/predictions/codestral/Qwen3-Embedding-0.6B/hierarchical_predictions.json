{
  "sqlfluff__sqlfluff-1625": {
    "instance_id": "sqlfluff__sqlfluff-1625",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/sqlfluff/rules/L031.py\n+++ b/src/sqlfluff/rules/L031.py\n@@ -1,5 +1,5 @@\n class Rule_L031(BaseRule):\n     \"\"\"Avoid table aliases in from clauses and join conditions.\n\n-    def _eval(self, segment, **kwargs):\n+    def _eval(self, segment, parent_stack, **kwargs):\n         \"\"\"Identify aliases in from clause and join conditions.\n\n         Find base table, table expressions in join, and other expressions in select clause\n@@ -10,6 +10,7 @@\n         if segment.is_type(\"select_statement\"):\n             # A buffer for all table expressions in join conditions\n             from_expression_elements = []\n+            join_clauses = []\n             column_reference_segments = []\n\n             from_clause_segment = segment.get_child(\"from_clause\")\n@@ -30,6 +31,11 @@\n             if not from_expression_element:\n                 return None\n             from_expression_element = from_expression_element.get_child(\n+                \"table_expression\"\n+            )\n+\n+            # Check if there are any join clauses in the query\n+            join_clauses = segment.recursive_crawl(\"join_clause\")\n+\n             # Find base table\n             base_table = None\n             if from_expression_element:\n@@ -40,7 +46,7 @@\n             from_clause_index = segment.segments.index(from_clause_segment)\n             from_clause_and_after = segment.segments[from_clause_index:]\n\n-            for clause in from_clause_and_after:\n+            for clause in from_clause_and_after + list(join_clauses):\n                 for from_expression_element in clause.recursive_crawl(\n                     \"from_expression_element\"\n                 ):\n@@ -50,7 +56,7 @@\n                 for column_reference in clause.recursive_crawl(\"column_reference\"):\n                     column_reference_segments.append(column_reference)\n\n-            return (\n-                self._lint_aliases_in_join(\n-                    base_table,\n-                    from_expression_elements,\n-                    column_reference_segments,\n-                    segment,\n-                )\n-                or None\n-            )\n+            # Only lint if there are join clauses or if it's a simple FROM clause with alias\n+            if join_clauses or (from_expression_elements and base_table):\n+                return (\n+                    self._lint_aliases_in_join(\n+                        base_table,\n+                        from_expression_elements,\n+                        column_reference_segments,\n+                        segment,\n+                    )\n+                    or None\n+                )\n         return None"
  },
  "sqlfluff__sqlfluff-2419": {
    "instance_id": "sqlfluff__sqlfluff-2419",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/sqlfluff/rules/L060.py\n+++ b/src/sqlfluff/rules/L060.py\n@@ -23,7 +23,7 @@\n     \"\"\"\n\n     def _eval(self, context: RuleContext) -> Optional[LintResult]:\n-        \"\"\"Use ``COALESCE`` instead of ``IFNULL`` or ``NVL``.\"\"\"\n+        \"\"\"Use ``COALESCE`` instead of ``IFNULL`` or ``NVL``. Specify which one to use.\"\"\"\n         # We only care about function names.\n         if context.segment.name != \"function_name_identifier\":\n             return None\n@@ -32,7 +32,11 @@\n         # Only care if the function is ``IFNULL`` or ``NVL``.\n         if context.segment.raw_upper not in {\"IFNULL\", \"NVL\"}:\n             return None\n-\n+        # Determine which function to suggest replacing\n+        wrong_function = \"IFNULL\" if context.segment.raw_upper == \"IFNULL\" else \"NVL\"\n+\n         # Create fix to replace ``IFNULL`` or ``NVL`` with ``COALESCE``.\n-        fix = LintFix.replace(\n+        fix = LintFix.replace(\n+            context.segment,\n+            [CodeSegment(raw=\"COALESCE\", name=\"function_name_identifier\", type=\"function_name_identifier\")],\n+            description=f\"Use 'COALESCE' instead of '{wrong_function}'\"\n         )\n\n         return LintResult(context.segment, [fix])\n\nL:  21 | P:   9 | L060 | Use 'COALESCE' instead of 'IFNULL'.\n\nL:  21 | P:   9 | L060 | Use 'COALESCE' instead of 'NVL'."
  },
  "sqlfluff__sqlfluff-1733": {
    "instance_id": "sqlfluff__sqlfluff-1733",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/sqlfluff/rules/L003.py\n+++ b/src/sqlfluff/rules/L003.py\n@@ -1002,7 +1002,7 @@ class Rule_L003(BaseRule):\n                     # Make fixes\n                     fixes = self._coerce_indent_to(\n                         desired_indent=desired_indent,\n-                        current_indent_buffer=this_line[\"indent_buffer\"],\n+                        current_indent_buffer=tuple(this_line[\"indent_buffer\"]),\n                         current_anchor=trigger_segment,\n                     )\n                     return LintResult("
  },
  "sqlfluff__sqlfluff-1517": {
    "instance_id": "sqlfluff__sqlfluff-1517",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/sqlfluff/core/parser/parser.py\n+++ b/src/sqlfluff/core/parser/parser.py\n@@ -28,6 +28,10 @@\n     def parse(self, string, dialect=None, config=None):\n         \"\"\"Parse a string into a segment tree.\n\n         Args:\n+            string (:obj:`str`): The string to parse.\n+            dialect (:obj:`str`, optional): The dialect to use for parsing.\n+            config (:obj:`dict`, optional): Configuration dictionary.\n+\n         Returns:\n             :obj:`BaseSegment`: The parsed segment tree.\n         \"\"\"\n@@ -35,7 +39,7 @@\n         if dialect is None:\n             dialect = self.dialect\n\n-        ctx = ParseContext(string, dialect=dialect, config=config)\n+        ctx = ParseContext(string.strip(), dialect=dialect, config=config)\n\n         # Get the root segment\n         root_segment = self.dialect.get_segment(\"file\")\n@@ -43,6 +47,10 @@\n         # Parse the string\n         parsed = root_segment.parse(parse_context=ctx)\n\n+        # Handle multiple semicolons at the end\n+        if parsed and parsed.is_type(\"file\") and len(parsed.segments) > 1:\n+            parsed.segments = [seg for seg in parsed.segments if not seg.is_type(\"semicolon\")]\n+\n         return parsed\n\n     def parse_string(self, string, dialect=None, config=None):"
  },
  "sqlfluff__sqlfluff-1763": {
    "instance_id": "sqlfluff__sqlfluff-1763",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/plugins/sqlfluff-templater-dbt/sqlfluff_templater_dbt/templater.py\n+++ b/plugins/sqlfluff-templater-dbt/sqlfluff_templater_dbt/templater.py\n@@ -1,4 +1,4 @@\n-import os\n+import os, sys\n from functools import partial\n from typing import Optional\n\n@@ -10,6 +10,7 @@\n from sqlfluff.core.errors import SQLTemplaterError, SQLTemplaterSkipFile\n from sqlfluff.core.templaters.base import TemplatedFile\n from sqlfluff.core.templaters.jinja import JinjaTemplater\n+from sqlfluff.utils.functional import cached_property\n\n class DbtTemplater(JinjaTemplater):\n     \"\"\"A templater using dbt.\"\"\"\n@@ -122,7 +123,7 @@\n         templater_logger.debug(\"    Node compiled SQL: %r\", compiled_sql)\n\n         # When using dbt-templater, trailing newlines are ALWAYS REMOVED during\n-        # compiling. Unless fixed (like below), this will cause:\n+        # compiling. Unless fixed (like below), this will cause:\n         #    1. L009 linting errors when running \"sqlfluff lint foo_bar.sql\"\n         #       since the linter will use the compiled code with the newlines\n         #       removed.\n@@ -131,7 +132,7 @@\n         #    2. \"No newline at end of file\" warnings in Git/GitHub since\n         #       sqlfluff uses the compiled SQL to write fixes back to the\n         #       source SQL in the dbt model.\n-        # The solution is:\n+        # The solution is:\n         #    1. Check for trailing newlines before compiling by looking at the\n         #       raw SQL in the source dbt file, store the count of trailing newlines.\n         #    2. Append the count from #1 above to the node.raw_sql and\n@@ -140,7 +141,7 @@\n         #       newlines removed by the dbt-templater.\n         node.raw_sql = node.raw_sql + \"\\n\" * n_trailing_newlines\n         compiled_sql = compiled_sql + \"\\n\" * n_trailing_newlines\n-\n+\n         raw_sliced, sliced_file, templated_sql = self.slice_file(\n             node.raw_sql,\n             compiled_sql,\n@@ -148,7 +149,7 @@\n             config=config,\n         )\n\n-        return (\n+        return (\n             TemplatedFile(\n                 source_str=node.raw_sql,\n                 templated_str=templated_sql,\n@@ -156,7 +157,7 @@\n                 raw_sliced=raw_sliced,\n             ),\n             # No violations returned in this way.\n-            [],\n+            [],\n         )"
  },
  "marshmallow-code__marshmallow-1359": {
    "instance_id": "marshmallow-code__marshmallow-1359",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/marshmallow/fields.py\n+++ b/src/marshmallow/fields.py\n@@ -1117,7 +1117,7 @@ class DateTime(Field):\n         self.format = format\n\n     def _bind_to_schema(self, field_name, schema):\n-        super()._bind_to_schema(field_name, schema)\n+        super(DateTime, self)._bind_to_schema(field_name, schema)\n         self.format = (\n             self.format\n             or getattr(schema.opts, self.SCHEMA_OPTS_VAR_NAME)"
  },
  "marshmallow-code__marshmallow-1343": {
    "instance_id": "marshmallow-code__marshmallow-1343",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/marshmallow/schema.py\n+++ b/src/marshmallow/schema.py\n@@ -885,7 +885,11 @@ class BaseSchema(base.SchemaABC):\n             validator = getattr(self, attr_name)\n             validator_kwargs = validator.__marshmallow_kwargs__[(VALIDATES, False)]\n             field_name = validator_kwargs['field_name']\n-            field_obj = self.fields[field_name]\n+\n+            try:\n+                field_obj = self.fields[field_name]\n+            except KeyError:\n+                continue\n\n             if many:\n                 for idx, item in enumerate(data):\n@@ -900,7 +904,11 @@ class BaseSchema(base.SchemaABC):\n                     pass\n                     else:\n                         validated_value = unmarshal.call_and_store(\n-                            getter_func=validator,\n+                            getter_func=lambda v: validator(v),\n                             data=value,\n                             field_name=field_obj.load_from or field_name,\n                             field_obj=field_obj,"
  },
  "pylint-dev__astroid-1978": {
    "instance_id": "pylint-dev__astroid-1978",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/astroid/brain/brain_numpy_utils.py\n+++ b/astroid/brain/brain_numpy_utils.py\n@@ -1,6 +1,7 @@\n import sys\n from typing import Callable, TypeVar, cast\n+import warnings\n\n _P = TypeVar(\"_P\")\n _R = TypeVar(\"_R\")\n@@ -10,6 +11,10 @@\n     Otherwise returns ('0', '0', '0')\n     \"\"\"\n     try:\n+        with warnings.catch_warnings():\n+            warnings.simplefilter(\"ignore\", FutureWarning)\n+            import numpy  # pylint: disable=import-outside-toplevel\n         return tuple(numpy.version.version.split(\".\"))\n     except (ImportError, AttributeError):\n         return (\"0\", \"0\", \"0\")"
  },
  "pylint-dev__astroid-1333": {
    "instance_id": "pylint-dev__astroid-1333",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/astroid/builder.py\n+++ b/astroid/builder.py\n@@ -100,7 +100,11 @@ class AstroidBuilder:\n             )\n         except UnicodeError as exc:  # wrong encoding\n             # detect_encoding returns utf-8 if no encoding specified\n-            raise AstroidBuildingError(\n+            if \"encoding\" in str(exc):\n+                raise AstroidBuildingError(\n+                    \"Wrong or no encoding specified for {filename}.\", filename=path\n+                ) from exc\n+            raise AstroidBuildingError(\"Unable to load file {path}: {error}\", path=path, error=exc) from exc\n         with stream:\n             # get module name if necessary\n             if modname is None:\n@@ -110,7 +114,7 @@ class AstroidBuilder:\n                     modname = os.path.splitext(os.path.basename(path))[0]\n             # build astroid representation\n             try:\n-                module = self._data_build(data, modname, path)\n+                module = self._data_build(data, modname, path) if data else None\n             except (SyntaxError, LookupError) as exc:\n                 raise AstroidSyntaxError(\n                     \"Python 3 encoding specification error or unknown encoding:\\n\"\n@@ -120,6 +124,10 @@ class AstroidBuilder:\n                 modname=modname,\n                 path=path,\n                 error=exc,\n+            ) from exc\n+            if module is None:\n+                raise AstroidBuildingError(\"Unable to build AST for empty file {path}\", path=path)\n+            return self._post_build(module, encoding)"
  },
  "pylint-dev__astroid-1196": {
    "instance_id": "pylint-dev__astroid-1196",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/astroid/nodes/node_classes.py\n+++ b/astroid/nodes/node_classes.py\n@@ -2248,7 +2248,7 @@ class Dict(NodeNG):\n         \"\"\"Get an item from this node.\n\n         :param index: The node to use as a subscript index.\n-        :type index: Const or Slice\n+        :type index: NodeNG\n\n         :raises AstroidTypeError: When the given index cannot be used as a\n             subscript index, or if this node is not subscriptable.\n         :raises AstroidIndexError: If the given index does not exist in the\n@@ -2255,12 +2255,12 @@ class Dict(NodeNG):\n         for key, value in self.items:\n             # TODO(cpopa): no support for overriding yet, {1:2, **{1: 3}}.\n             if isinstance(key, DictUnpack):\n-                try:\n-                    return value.getitem(index, context)\n-                except (AstroidTypeError, AstroidIndexError):\n-                    continue\n+                try:\n+                    result = value.getitem(index, context)\n+                    if result is not None:\n+                        return result\n+                except (AstroidTypeError, AstroidIndexError):\n+                    continue\n             for inferredkey in key.infer(context):\n                 if inferredkey is util.Uninferable:\n                     continue\n@@ -2270,7 +2270,7 @@ class Dict(NodeNG):\n                     if inferredkey.value == index.value:\n                         return value\n\n-        raise AstroidIndexError(index)\n+        raise AstroidIndexError(index, context=context)"
  },
  "pylint-dev__astroid-1866": {
    "instance_id": "pylint-dev__astroid-1866",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/astroid/brain/brain_builtin_inference.py\n+++ b/astroid/brain/brain_builtin_inference.py\n@@ -940,6 +940,10 @@\n     if isinstance(node.func.expr, nodes.Name):\n         value: nodes.Const = helpers.safe_infer(node.func.expr)\n     else:\n+        if not isinstance(node.func.expr, nodes.Const):\n+            return iter([util.Uninferable])\n+        value = node.func.expr\n+\n     format_template = value.value\n\n     # Check if format_template is a string\n@@ -947,6 +951,8 @@\n     if not isinstance(format_template, str):\n         return iter([util.Uninferable])\n\n+    # Check if format_template is not None\n+    if format_template is None:\n+        return iter([util.Uninferable])\n\n     # Get the positional arguments passed\n     inferred_positional = ["
  },
  "pylint-dev__astroid-1268": {
    "instance_id": "pylint-dev__astroid-1268",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/astroid/nodes/as_string.py\n+++ b/astroid/nodes/as_string.py\n@@ -1,4 +1,5 @@\n+from astroid.nodes import Unknown\n from astroid.nodes import (\n     AssignAttr,\n     Attribute,\n@@ -10,6 +11,7 @@\n     Tuple,\n     UnaryOp,\n     Yield,\n+    Unknown,\n )\n\n class AsStringVisitor:\n@@ -56,6 +58,10 @@\n         return node.accept(self).replace(DOC_NEWLINE, \"\\n\")\n\n     def _docs_dedent(self, doc):\n+        \"\"\"Stop newlines in docs being indented by self._stmt_list\"\"\"\n+        return '\\n{}\"\"\"{}\"\"\"'.format(self.indent, doc.replace(\"\\n\", DOC_NEWLINE))\n+\n+    def visit_unknown(self, node: Unknown) -> str:\n+        \"\"\"Return an astroid.Unknown node as string.\"\"\"\n+        return \"<unknown>\"\n+\n     def _stmt_list(self, stmts, indent=True):\n         \"\"\"return a list of nodes to string\"\"\"\n         stmts = \"\\n\".join(nstr for nstr in [nstr.accept(self) for nstr in stmts] if nstr)"
  },
  "pyvista__pyvista-4315": {
    "instance_id": "pyvista__pyvista-4315",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/pyvista/core/grid.py\n+++ b/pyvista/core/grid.py\n@@ -102,7 +102,7 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n         if len(args) == 1:\n             if isinstance(args[0], _vtk.vtkRectilinearGrid):\n                 if deep:\n-                    self.deep_copy(args[0])\n+                    self.deep_copy(args[0]) if deep else self.shallow_copy(args[0])\n                 else:\n                     self.shallow_copy(args[0])\n             elif isinstance(args[0], (str, pathlib.Path)):\n@@ -118,7 +118,7 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n                 self._from_arrays(args[0], None, None, check_duplicates)\n             else:\n                 raise TypeError(f'Type ({type(args[0])}) not understood by `RectilinearGrid`')\n-        elif len(args) == 3 or len(args) == 2:\n+        elif len(args) == 3 or len(args) == 2 or len(args) == 1:\n             arg0_is_arr = isinstance(args[0], np.ndarray)\n             arg1_is_arr = isinstance(args[1], np.ndarray) if len(args) > 1 else False\n             if len(args) == 3:\n@@ -126,7 +126,7 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n             else:\n                 arg2_is_arr = False\n\n-            if all([arg0_is_arr, arg1_is_arr, arg2_is_arr]):\n+            if all([arg0_is_arr, arg1_is_arr]) and (len(args) == 2 or arg2_is_arr):\n                 self._from_arrays(args[0], args[1], args[2] if len(args) == 3 else None, check_duplicates)\n             elif all([arg0_is_arr, arg1_is_arr]):\n                 self._from_arrays(args[0], args[1], None, check_duplicates)\n@@ -142,7 +142,7 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n         if check_duplicates:\n             raise_has_duplicates(x)\n\n-        # edges are shown as triangles if x is not floating point\n+        # edges are shown as triangles if x is not floating point or is a sequence\n         if not np.issubdtype(x.dtype, np.floating):\n             x = x.astype(float)\n         self.SetXCoordinates(helpers.convert_array(x.ravel()))"
  }
}