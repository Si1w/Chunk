{
  "sqlfluff__sqlfluff-1625": {
    "instance_id": "sqlfluff__sqlfluff-1625",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/sqlfluff/rules/L031.py\n+++ b/src/sqlfluff/rules/L031.py\n@@ -1,5 +1,5 @@\n \"\"\"Implementation of Rule L031.\"\"\"\n from collections import Counter, defaultdict\n-from typing import Generator, NamedTuple\n+from typing import Generator, NamedTuple, Optional\n from sqlfluff.core.parser import BaseSegment\n from sqlfluff.core.rules.base import BaseRule, LintFix, LintResult\n from sqlfluff.core.rules.doc_decorators import document_fix_compatible\n@@ -102,7 +102,7 @@\n         # If this is self-join - skip it\n         if (\n             base_table\n-            and base_table.raw == table_ref.raw\n+            and base_table.raw == table_ref.raw\n             and base_table != table_ref\n         ):\n             continue\n@@ -122,7 +122,7 @@\n         # For each aliased table, check whether to keep or remove it.\n         for alias_info in to_check:\n             # If the same table appears more than once in the FROM clause with\n-            # different alias names, do not consider removing its aliases.\n+            # different alias names, do not consider removing its aliases.\n             # The aliases may have been introduced simply to make each\n             # occurrence of the table independent within the query.\n             if (\n@@ -131,7 +131,7 @@\n                 and len(table_aliases[alias_info.table_ref.raw]) > 1\n             ):\n                 continue\n-            select_clause = segment.get_child(\"select_clause\")\n+            select_clause = segment.get_child(\"select_clause\")\n             ids_refs = []\n             # Find all references to alias in select clause\n             alias_name = alias_info.alias_identifier_ref.raw\n@@ -140,7 +140,7 @@\n                 used_alias_ref = alias_with_column.get_child(\"identifier\")\n                 if used_alias_ref and used_alias_ref.raw == alias_name:\n                     ids_refs.append(used_alias_ref)\n-            # Find all references to alias in column references\n+            # Find all references to alias in column references\n             for exp_ref in column_reference_segments:\n                 used_alias_ref = exp_ref.get_child(\"identifier\")\n                 # exp_ref.get_child('dot') ensures that the column reference includes a table reference\n@@ -150,7 +150,7 @@\n             # Fixes for deleting ` as sth` and for editing references to aliased tables\n             fixes = [\n                 *[\n-                    LintFix(\"delete\", d)\n+                    LintFix(\"delete\", d)\n                     for d in [alias_info.alias_exp_ref, alias_info.whitespace_ref]\n                 ],\n                 *["
  },
  "sqlfluff__sqlfluff-2419": {
    "instance_id": "sqlfluff__sqlfluff-2419",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/sqlfluff/rules/L060.py\n+++ b/src/sqlfluff/rules/L060.py\n@@ -23,7 +23,7 @@ class Rule_L060(BaseRule):\n     \"\"\"Use ``COALESCE`` instead of ``IFNULL`` or ``NVL``.\n     | **Anti-pattern**\n     | ``IFNULL`` or ``NVL`` are used to fill ``NULL`` values.\n-    .. code-block:: sql\n+    .. code-block:: sql\n         SELECT ifnull(foo, 0) AS bar,\n         FROM baz;\n         SELECT nvl(foo, 0) AS bar,\n@@ -33,7 +33,7 @@ class Rule_L060(BaseRule):\n     | ``COALESCE`` is universally supported,\n     | whereas Redshift doesn't support ``IFNULL``\n     | and BigQuery doesn't support ``NVL``.\n-    .. code-block:: sql\n+    .. code-block:: sql\n         SELECT coalesce(foo, 0) AS bar,\n         FROM baz;\n     \"\"\"\n@@ -42,7 +42,7 @@ class Rule_L060(BaseRule):\n     def _eval(self, context: RuleContext) -> Optional[LintResult]:\n         \"\"\"Use ``COALESCE`` instead of ``IFNULL`` or ``NVL``.\"\"\"\n         # We only care about function names.\n-        if context.segment.name != \"function_name_identifier\":\n+        if context.segment.name != \"function_name\":\n             return None\n         # Only care if the function is ``IFNULL`` or ``NVL``.\n         if context.segment.raw_upper not in {\"IFNULL\", \"NVL\"}:\n@@ -50,7 +50,11 @@ class Rule_L060(BaseRule):\n             CodeSegment(\n                 raw=\"COALESCE\",\n                 name=\"function_name_identifier\",\n-                type=\"function_name_identifier\",\n+                type=\"function_name\",\n+            )\n+        ]\n+        # Create specific error message based on the function used\n+        if context.segment.raw_upper == \"IFNULL\":\n+            description = \"Use 'COALESCE' instead of 'IFNULL'.\"\n+        else:\n+            description = \"Use 'COALESCE' instead of 'NVL'.\"\n         return LintResult(\n             context.segment,\n             [fix],"
  },
  "sqlfluff__sqlfluff-1733": {
    "instance_id": "sqlfluff__sqlfluff-1733",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/sqlfluff/rules/L018.py\n+++ b/src/sqlfluff/rules/L018.py\n@@ -102,7 +102,7 @@ class Rule_L018(BaseRule):\n                     # We can move it back, it's all whitespace\n                     fixes = [\n                         LintFix(\n-                            \"create\",\n+                            \"edit\",\n                             seg,\n                             [WhitespaceSegment(with_indent_str)],\n                         )\n@@ -111,7 +111,7 @@ class Rule_L018(BaseRule):\n                     # We have to move it to a newline\n                     fixes = [\n                         LintFix(\n-                            \"create\",\n+                            \"edit\",\n                             seg,\n                             [\n                                 NewlineSegment(),"
  },
  "sqlfluff__sqlfluff-1517": {
    "instance_id": "sqlfluff__sqlfluff-1517",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/sqlfluff/core/parser/grammar/sequence.py\n+++ b/src/sqlfluff/core/parser/grammar/sequence.py\n@@ -120,7 +120,7 @@ class Sequence(BaseGrammar):\n         # Buffers of uninstantiated meta segments.\n         meta_pre_nc = ()\n         meta_post_nc = ()\n-        early_break = False\n+        early_break = True  # Default to early break to handle trailing semicolons\n\n         for idx, elem in enumerate(self._elements):\n             # Check for an early break.\n@@ -130,7 +130,7 @@ class Sequence(BaseGrammar):\n             while True:\n                 # Consume non-code if appropriate\n                 if self.allow_gaps:\n-                    pre_nc, mid_seg, post_nc = trim_non_code_segments(\n+                    pre_nc, mid_seg, post_nc = trim_non_code_segments(\n                         unmatched_segments\n                     )\n                 else:\n@@ -142,7 +142,7 @@ class Sequence(BaseGrammar):\n                     # We've run our of sequence without matching everything.\n                     # Do only optional or meta elements remain?\n                     if all(\n-                        e.is_optional() or e.is_meta or isinstance(e, Conditional)\n+                        e.is_optional() or e.is_meta or isinstance(e, Conditional) or e.is_type(\"semicolon\")\n                         for e in self._elements[idx:]\n                     ):\n                         # then it's ok, and we can return what we've got so far.\n@@ -153,7 +153,7 @@ class Sequence(BaseGrammar):\n                         # If it's meta, instantiate it.\n                         if e.is_meta:\n                             meta_post_nc += (e(),)  # pragma: no cover TODO?\n-                        # If it's conditional and it's enabled, match it.\n+                        # If it's conditional, semicolon, or enabled, match it.\n                         if isinstance(e, Conditional) and e.is_enabled(\n                             parse_context\n                         ):\n@@ -161,7 +161,7 @@ class Sequence(BaseGrammar):\n                     # Early break to exit via the happy match path.\n                     early_break = True\n                     break\n-                else:\n+                elif not early_break:\n                     # we've got to the end of the sequence without matching all\n                     # required elements.\n                     return MatchResult.from_unmatched(segments)"
  },
  "sqlfluff__sqlfluff-1763": {
    "instance_id": "sqlfluff__sqlfluff-1763",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/sqlfluff/core/file_helpers.py\n+++ b/src/sqlfluff/core/file_helpers.py\n@@ -1,4 +1,4 @@\n \"\"\"File helpers - functions to help with file handling.\"\"\"\n-import os\n+import os, codecs\n from typing import Optional, Tuple\n from sqlfluff.core.config import FluffConfig\n\n@@ -12,6 +12,12 @@\n     \"\"\"Get the encoding of a file.\"\"\"\n     # If the encoding is specified in the config, use that\n     if config and config.get(\"file_encoding\"):\n+        # Handle special case for 'charmap' encoding which can't handle Unicode\n+        if config.get(\"file_encoding\") == \"charmap\":\n+            # Fall back to UTF-8 which can handle Unicode\n+            config.set_value(\"file_encoding\", \"utf-8\")\n+            return \"utf-8\"\n+        else:\n             return config.get(\"file_encoding\")\n     # Otherwise try to detect it\n     try:\n@@ -20,7 +26,7 @@\n         with open(fname, \"rb\") as f:\n             raw = f.read(4)\n         if raw.startswith(codecs.BOM_UTF8):\n-            return \"utf-8-sig\"\n+            return \"utf-8\"\n     except (IOError, OSError):\n         pass\n     # Default to UTF-8"
  },
  "marshmallow-code__marshmallow-1359": {
    "instance_id": "marshmallow-code__marshmallow-1359",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/marshmallow/fields.py\n+++ b/src/marshmallow/fields.py\n@@ -1117,7 +1117,7 @@ class List(Field):\n         self.inner = copy.deepcopy(self.inner)\n         self.inner._bind_to_schema(field_name, self)\n         if isinstance(self.inner, Nested):\n-            self.inner.only = self.only\n+            self.inner.only = self.inner.only or self.only\n             self.inner.exclude = self.exclude"
  },
  "marshmallow-code__marshmallow-1343": {
    "instance_id": "marshmallow-code__marshmallow-1343",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/src/marshmallow/schema.py\n+++ b/src/marshmallow/schema.py\n@@ -894,7 +894,7 @@ class Schema(with_metaclass(SchemaMeta, BaseSchema)):\n     def _invoke_field_validators(self, unmarshal, data, many):\n         for attr_name in self.__processors__[(VALIDATES, False)]:\n             validator = getattr(self, attr_name)\n-            validator_kwargs = validator.__marshmallow_kwargs__[(VALIDATES, False)]\n+            validator_kwargs = validator.__marshmallow_kwargs__.get((VALIDATES, False), {})\n             field_name = validator_kwargs['field_name']\n             try:\n                 field_obj = self.fields[field_name]"
  },
  "pylint-dev__astroid-1978": {
    "instance_id": "pylint-dev__astroid-1978",
    "model_name_or_path": "codestral-latest",
    "model_patch": "Here's the patch file to resolve the deprecation warnings from numpy:\n\n```patch\n--- a/astroid/brain/brain_numpy_core_numerictypes.py\n+++ b/astroid/brain/brain_numpy_core_numerictypes.py\n@@ -1,5 +1,5 @@\n # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n # For details: https://github.com/PyCQA/astroid/blob/main/LICENSE\n # Copyright (c) https://github.com/PyCQA/astroid/blob/main/CONTRIBUTORS.txt\n-# TODO(hippo91) : correct the methods signature.\n+# TODO(hippo91) : correct the methods signature and address numpy deprecation warnings.\n \"\"\"Astroid hooks for numpy.core.numerictypes module.\"\"\"\n from astroid.brain.brain_numpy_utils import numpy_supports_type_hints\n from astroid.brain.helpers import register_module_extender\n@@ -10,6 +10,7 @@\n     #       According to numpy doc the generic object should expose\n     #       the same API than ndarray. This has been done here partially\n     #       through the astype method.\n+    import numpy as np\n     generic_src = \"\"\"\n     class generic(object):\n         def __init__(self, value):\n@@ -17,7 +18,7 @@\n             self.base = None\n             self.data = None\n             self.dtype = None\n-            self.flags = None\n+            self.flags = np.ndarray([0, 0])\n             # Should be a numpy.flatiter instance but not available for now\n             # Putting an array instead so that iteration and indexing are authorized\n             self.flat = np.ndarray([0, 0])\n@@ -25,7 +26,7 @@\n         def astype(self, dtype, order='K', casting='unsafe', subok=True, copy=True): return np.ndarray([0, 0])\n         def base(self): return uninferable\n         def byteswap(self): return uninferable\n-        def choose(self): return uninferable\n+        def choose(self, choices, out=None, mode='raise'): return np.ndarray([0, 0])\n         def clip(self): return uninferable\n         def compress(self): return uninferable\n         def conj(self): return uninferable\n@@ -33,7 +34,7 @@\n         def copy(self): return uninferable\n         def cumprod(self): return uninferable\n         def cumsum(self): return uninferable\n-        def data(self): return uninferable\n+        def data(self, buffer=None, offset=0, strides=None, order=None): return np.ndarray([0, 0])\n         def diagonal(self): return uninferable\n         def dtype(self): return uninferable\n         def dump(self): return uninferable\n@@ -41,7 +42,7 @@\n         def fill(self): return uninferable\n         def flags(self): return uninferable\n         def flat(self): return uninferable\n-        def flatten(self): return uninferable\n+        def flatten(self, order='C'): return np.ndarray([0, 0])\n         def getfield(self): return uninferable\n         def imag(self): return uninferable\n         def item(self): return uninferable\n@@ -49,7 +50,7 @@\n         def itemsize(self): return uninferable\n         def max(self): return uninferable\n         def mean(self): return uninferable\n-        def min(self): return uninferable\n+        def min(self, axis=None, out=None, keepdims=False): return np.ndarray([0, 0])\n         def nbytes(self): return uninferable\n         def ndim(self): return uninferable\n         def newbyteorder(self): return uninferable\n@@ -57,7 +58,7 @@\n         def prod(self): return uninferable\n         def ptp(self): return uninferable\n         def put(self): return uninferable\n-        def ravel(self): return uninferable\n+        def ravel(self, order='C'): return np.ndarray([0, 0])\n         def real(self): return uninferable\n         def repeat(self): return uninferable\n         def reshape(self): return uninferable\n@@ -65,7 +66,7 @@\n         def searchsorted(self): return uninferable\n         def setfield(self): return uninferable\n         def setflags(self): return uninferable\n-        def shape(self): return uninferable\n+        def shape(self, newshape=None, order='C'): return np.ndarray([0, 0])\n         def size(self): return uninferable\n         def sort(self): return uninferable\n         def squeeze(self): return uninferable\n@@ -73,7 +74,7 @@\n         def sum(self): return uninferable\n         def swapaxes(self): return uninferable\n         def take(self): return uninferable\n-        def tobytes(self): return uninferable\n+        def tobytes(self, order='C'): return b''\n         def tofile(self): return uninferable\n         def tolist(self): return uninferable\n         def tostring(self): return uninferable\n@@ -81,7 +82,7 @@\n         def transpose(self): return uninferable\n         def var(self): return uninferable\n         def view(self): return uninferable\n-        \"\"\"\n+        \"\"\"\n     if numpy_supports_type_hints():\n         generic_src += \"\"\"\n         @classmethod\n@@ -102,7 +103,7 @@\n     return parse(\n         generic_src\n         + \"\"\"\n-    class dtype(object):\n+    class dtype(np.generic):\n         def __init__(self, obj, align=False, copy=False):\n             self.alignment = None\n             self.base = None\n@@ -111,7 +112,7 @@\n             self.hasobject = None\n             self.isalignedstruct = None\n             self.isbuiltin = None\n-            self.isnative = None\n+            self.isnative = np.ndarray([0, 0])\n             self.itemsize = None\n             self.kind = None\n             self.metadata = None\n@@ -120,7 +121,7 @@\n             self.str = None\n             self.subdtype = None\n             self.type = None\n-        def newbyteorder(self, new_order='S'): return uninferable\n+        def newbyteorder(self, new_order='S'): return np.ndarray([0, 0])\n         def __neg__(self): return uninferable\n     class busdaycalendar(object):\n         def __init__(self, weekmask='1111100', holidays=None):\n@@ -128,7 +129,7 @@\n     class flexible(generic): pass\n     class bool_(generic): pass\n     class number(generic):\n-        def __neg__(self): return uninferable\n+        def __neg__(self): return np.ndarray([0, 0])\n     class datetime64(generic):\n         def __init__(self, nb, unit=None): pass\n     class void(flexible):\n@@ -136,7 +137,7 @@\n             self.dtype = None\n             self.flags = None\n         def getfield(self): return uninferable\n-        def setfield(self): return uninferable\n+        def setfield(self, val, dtype, offset=0): return np.ndarray([0, 0])\n     class character(flexible): pass\n     class integer(number):\n         def __init__(self, value):\n@@ -144,7 +145,7 @@\n     class inexact(number): pass\n     class str_(str, character):\n         def maketrans(self, x, y=None, z=None): return uninferable\n-    class bytes_(bytes, character):\n+    class bytes_(bytes, character, np.generic):\n         def fromhex(self, string): return uninferable\n         def maketrans(self, frm, to): return uninferable\n     class signedinteger(integer): pass\n@@ -152,7 +153,7 @@\n     class unsignedinteger(integer): pass\n     class complexfloating(inexact): pass\n     class floating(inexact): pass\n-    class float64(floating, float):\n+    class float64(floating, float, np.generic):\n         def fromhex(self, string): return uninferable\n     class uint64(unsignedinteger): pass\n     class complex64(complexfloating): pass\n@@ -160,7 +161,7 @@\n     class float96(floating): pass\n     class int8(signedinteger): pass\n     class uint32(unsignedinteger): pass\n-    class uint8(unsignedinteger"
  },
  "pylint-dev__astroid-1333": {
    "instance_id": "pylint-dev__astroid-1333",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/astroid/builder.py\n+++ b/astroid/builder.py\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2006-2011, 2013-2014 LOGILAB S.A. (Paris, FRANCE) <contact@logilab.fr>\n+# Copyright (c) 2006-2011, 2013-2014 LOGILAB S.A. (Paris, FRANCE) <contact@logilab.fr>\n # Copyright (c) 2013 Phil Schaf <flying-sheep@web.de>\n # Copyright (c) 2014-2020 Claudiu Popa <pcmanticore@gmail.com>\n # Copyright (c) 2014-2015 Google, Inc.\n@@ -12,6 +12,7 @@\n # Copyright (c) 2021 Marc Mueller <30130371+cdce8p@users.noreply.github.com>\n # Copyright (c) 2021 Andrew Haigh <hello@nelf.in>\n # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n+# For details: https://github.com/PyCQA/astroid/blob/main/LICENSE\n \"\"\"The AstroidBuilder makes astroid from living object and / or from _ast\n The builder is not thread safe and can't be used to parse different sources\n at the same time.\n@@ -152,6 +153,10 @@\n         if modname is None:\n             try:\n                 modname = \".\".join(modutils.modpath_from_file(path))\n+            except ImportError:\n+                # If we can't determine the module name from the path,\n+                # use the filename as the module name\n+                modname = os.path.splitext(os.path.basename(path))[0]\n         if modname in self.astroid_cache and self.astroid_cache[modname].file == path:\n             return self.astroid_cache[modname]\n         if source:\n@@ -202,6 +207,10 @@\n         if modname is None:\n             try:\n                 modname = \".\".join(modutils.modpath_from_file(path))\n+            except ImportError:\n+                # If we can't determine the module name from the path,\n+                # use the filename as the module name\n+                modname = os.path.splitext(os.path.basename(path))[0]\n         if modname in self.astroid_cache and self.astroid_cache[modname].file == path:\n             return self.astroid_cache[modname]\n         if source:"
  },
  "pylint-dev__astroid-1196": {
    "instance_id": "pylint-dev__astroid-1196",
    "model_name_or_path": "codestral-latest",
    "model_patch": "```patch\n--- a/astroid/nodes/node_classes.py\n+++ b/astroid/nodes/node_classes.py\n@@ -1,4 +1,5 @@\n # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n # For details: https://github.com/PyCQA/astroid/blob/main/LICENSE\n # Copyright (c) https://github.com/PyCQA/astroid/blob/main/CONTRIBUTORS.txt\n+from __future__ import annotations\n \"\"\"Module for some node classes. More nodes in scoped_nodes.py\"\"\"\n from __future__ import annotations\n import abc\n@@ -122,6 +123,10 @@\n     \"\"\"return true if the two given statements are mutually exclusive\n     `exceptions` may be a list of exception names. If specified, discard If\n     branches and check one of the statement is in an exception handler catching\n+    one of the given exceptions.\n+    \"\"\"\n+    # index stmt1's parents\n+    stmt1_parents = {}\n     children = {}\n     previous = stmt1\n     for node in stmt1.node_ancestors():\n@@ -130,6 +135,7 @@\n         stmt1_parents[node] = 1\n         children[node] = previous\n         previous = node\n+    # climb among stmt2's parents until we find a common parent\n     previous = stmt2\n     for node in stmt2.node_ancestors():\n         if node in stmt1_parents:\n@@ -140,6 +146,10 @@\n                 if (\n                     node.locate_child(previous)[1]\n                     is not node.locate_child(children[node])[1]\n+                ):\n+                    return True\n+            elif isinstance(node, TryExcept):\n+                c2attr, c2node = node.locate_child(previous)\n                 c1attr, c1node = node.locate_child(children[node])\n                 if c1node is not c2node:\n                     first_in_body_caught_by_handlers = (\n@@ -151,6 +161,10 @@\n                         c2attr == \"orelse\" and c1attr == \"handlers\"\n                     )\n                     if any(\n+                        (\n+                            first_in_body_caught_by_handlers,\n+                            second_in_body_caught_by_handlers,\n+                            first_in_else_other_in_handlers,\n+                            second_in_else_other_in_handlers,\n                         )\n                     ):\n                         return True\n@@ -160,6 +174,7 @@\n     return False\n # getitem() helpers.\n _SLICE_SENTINEL = object()\n+def _slice_value(index, context=None):\n     \"\"\"Get the value of the given slice index.\"\"\"\n     if isinstance(index, Const):\n         if isinstance(index.value, (int, type(None))):\n@@ -168,6 +183,10 @@\n     else:\n         # Try to infer what the index actually is.\n         # Since we can't return all the possible values,\n+        # we'll stop at the first possible value.\n+        try:\n+            inferred = next(index.infer(context=context))\n+        except (InferenceError, StopIteration):\n+            pass\n         else:\n             if isinstance(inferred, Const):\n                 if isinstance(inferred.value, (int, type(None))):\n@@ -175,6 +194,7 @@\n     # Use a sentinel, because None can be a valid\n     # value that this function can return,\n     # as it is the case for unspecified bounds.\n+    return _SLICE_SENTINEL\n def _infer_slice(node, context=None):\n     lower = _slice_value(node.lower, context)\n     upper = _slice_value(node.upper, context)\n@@ -182,6 +202,7 @@\n     if all(elem is not _SLICE_SENTINEL for elem in (lower, upper, step)):\n         return slice(lower, upper, step)\n     raise AstroidTypeError(\n+        message=\"Could not infer slice used in subscript\",\n         node=node,\n         index=node.parent,\n         context=context,\n@@ -190,6 +211,7 @@\n     \"\"\"Get a slice or an item, using the given *index*, for the given sequence.\"\"\"\n     try:\n         if isinstance(index, Slice):\n+            index_slice = _infer_slice(index, context=context)\n             new_cls = instance.__class__()\n             new_cls.elts = elts[index_slice]\n             new_cls.parent = instance.parent\n@@ -198,6 +220,7 @@\n         if isinstance(index, Const):\n             return elts[index.value]\n     except IndexError as exc:\n+        raise AstroidIndexError(\n+            message=\"Index {index!s} out of range\",\n             node=instance,\n             index=index,\n             context=context,\n@@ -206,6 +229,7 @@\n         raise AstroidTypeError(\n             message=\"Type error {error!r}\", node=instance, index=index, context=context\n         ) from exc\n+    raise AstroidTypeError(f\"Could not use {index} as subscript index\")\n class Statement(NodeNG):\n     \"\"\"Statement node adding a few attributes\"\"\"\n     is_statement = True\n@@ -215,6 +239,7 @@\n     def next_sibling(self):\n         \"\"\"The next sibling statement node.\n         :returns: The next sibling statement node.\n+        :rtype: NodeNG or None\n         \"\"\"\n         stmts = self.parent.child_sequence(self)\n         index = stmts.index(self)\n@@ -224,6 +249,7 @@\n     def previous_sibling(self):\n         \"\"\"The previous sibling statement.\n         :returns: The previous sibling statement node.\n+        :rtype: NodeNG or None\n         \"\"\"\n         stmts = self.parent.child_sequence(self)\n         index = stmts.index(self)\n@@ -233,6 +259,7 @@\n     \"\"\"Base class for Set, FrozenSet, Tuple and List.\"\"\"\n     _astroid_fields = (\"elts\",)\n     def __init__(\n+        self,\n         lineno: int | None = None,\n         col_offset: int | None = None,\n         parent: NodeNG | None = None,\n@@ -241,6 +268,7 @@\n         :param end_lineno: The last line this node appears on in the source code.\n         :param end_col_offset: The end column this node appears on in the\n             source code. Note: This is after the last symbol.\n+        \"\"\"\n         self.elts: list[NodeNG] = []\n         \"\"\"The elements in the node.\"\"\"\n         super().__init__(\n@@ -250,6 +278,7 @@\n     def postinit(self, elts: list[NodeNG]) -> None:\n         \"\"\"Do some setup after initialisation.\n         :param elts: The list of elements the that node contains.\n+        \"\"\"\n         self.elts = elts\n     @classmethod\n     def from_elements(cls, elts=None):\n@@ -258,6 +287,7 @@\n         \"\"\"Create a node of this type from the given list of elements.\n         :param elts: The list of elements that the node should contain.\n         :type elts: list(NodeNG)\n+        :returns: A new node containing the given elements.\n         :rtype: NodeNG\n         \"\"\"\n         node = cls()\n@@ -265,6 +295,7 @@\n             node.elts = []\n         else:\n             node.elts = [const_factory(e) if _is_const(e) else e for e in elts]\n+        return node\n     def itered(self):\n         \"\"\"An iterator over the elements this node contains.\n         :returns: The contents of this node.\n@@ -272,6 +303,7 @@\n         return bool(self.elts)\n     @abc.abstractmethod\n     def pytype(self):\n+        \"\"\"Get the name of the type that this node represents.\n         :returns: The name of the type.\n         :rtype: str\n         \"\"\"\n@@ -280,6 +312,7 @@\n     def get_children(self):\n         yield from self.elts\n class LookupMixIn:\n+    \"\"\"Mixin to look up a name in the right scope.\"\"\"\n     \"\"\"Lookup where the given variable is assigned.\n     The lookup starts from self's scope. If self is not a frame itself\n     and the name is found in the inner frame locals, statements will be\n@@ -288,6 +321,7 @@\n     :param name: The name of the variable to find assignments for.\n     :returns: The scope node and the list of assignments associated to the\n         given name according to the scope where it has been found (locals,\n+        globals or builtin).\n     \"\"\"\n     return self.scope().scope_lookup(self, name)\n     def ilookup(self, name):\n@@ -295,6 +329,7 @@\n         :param name: The variable name to find values for.\n         :type name: str\n         :returns: The inferred values of the statements returned from\n+        :meth:`lookup`.\n         :rtype: iter"
  },
  "pylint-dev__astroid-1866": {
    "instance_id": "pylint-dev__astroid-1866",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/astroid/brain/brain_builtin_inference.py\n+++ b/astroid/brain/brain_builtin_inference.py\n@@ -956,7 +956,7 @@ def _infer_str_format_call(\n     # Get the positional arguments passed\n     inferred_positional = [\n         helpers.safe_infer(i, context) for i in call.positional_arguments\n-    ]\n+    ] if call.positional_arguments else []\n     if not all(isinstance(i, nodes.Const) for i in inferred_positional):\n         return iter([util.Uninferable])\n     pos_values: list[str] = [i.value for i in inferred_positional]\n@@ -964,7 +964,7 @@ def _infer_str_format_call(\n     # Get the keyword arguments passed\n     inferred_keyword = {\n         k: helpers.safe_infer(v, context) for k, v in call.keyword_arguments.items()\n-    } if call.keyword_arguments else {}\n+    } if call.keyword_arguments else {}\n     if not all(isinstance(i, nodes.Const) for i in inferred_keyword.values()):\n         return iter([util.Uninferable])\n     keyword_values: dict[str, str] = {k: v.value for k, v in inferred_keyword.items()}"
  },
  "pylint-dev__astroid-1268": {
    "instance_id": "pylint-dev__astroid-1268",
    "model_name_or_path": "codestral-latest",
    "model_patch": "```python\n--- a/astroid/nodes/as_string.py\n+++ b/astroid/nodes/as_string.py\n@@ -56,6 +56,7 @@ class AsStringVisitor:\n         return node.accept(self).replace(DOC_NEWLINE, \"\\n\")\n\n     def _docs_dedent(self, doc):\n+        \"\"\"Stop newlines in docs being indented by self._stmt_list\"\"\"\n         \"\"\"Stop newlines in docs being indented by self._stmt_list\"\"\"\n         return '\\n{}\"\"\"{}\"\"\"'.format(self.indent, doc.replace(\"\\n\", DOC_NEWLINE))\n\n@@ -102,6 +103,7 @@ class AsStringVisitor:\n         \"\"\"return a list of nodes to string\"\"\"\n         stmts = \"\\n\".join(nstr for nstr in [n.accept(self) for n in stmts] if nstr)\n         if indent:\n+            \"\"\"return a list of nodes to string\"\"\"\n             return self.indent + stmts.replace(\"\\n\", \"\\n\" + self.indent)\n         return stmts\n\n@@ -110,6 +112,7 @@ class AsStringVisitor:\n         \"\"\"Wrap child in parens only if required to keep same semantics\"\"\"\n         if self._should_wrap(node, child, is_left):\n             return f\"({child.accept(self)})\"\n+            \"\"\"Wrap child in parens only if required to keep same semantics\"\"\"\n         return child.accept(self)\n\n     def _should_wrap(self, node, child, is_left):\n@@ -118,6 +121,7 @@ class AsStringVisitor:\n         if node_precedence > child_precedence:\n             # 3 * (4 + 5)\n             return True\n+            \"\"\"Wrap child in parens only if required to keep same semantics\"\"\"\n         if (\n             node_precedence == child_precedence\n             and is_left != node.op_left_associative()\n@@ -126,6 +130,7 @@ class AsStringVisitor:\n             # (2**3)**4\n             return True\n         return False\n+            \"\"\"Wrap child in parens only if required to keep same semantics\"\"\"\n\n     # visit_<node> methods ###########################################\n     def visit_await(self, node):\n@@ -134,6 +139,7 @@ class AsStringVisitor:\n         return f\"async {self.visit_with(node)}\"\n\n     def visit_asyncfor(self, node):\n+        \"\"\"return an astroid.AsyncFor node as string\"\"\"\n         return f\"async {self.visit_for(node)}\"\n\n     def visit_arguments(self, node):\n@@ -142,6 +148,7 @@ class AsStringVisitor:\n         \"\"\"return an astroid.Function node as string\"\"\"\n         return node.format_args()\n\n+    \"\"\"return an astroid.AssAttr node as string\"\"\"\n     def visit_assignattr(self, node):\n         \"\"\"return an astroid.AssAttr node as string\"\"\"\n         return self.visit_attribute(node)\n@@ -150,6 +157,7 @@ class AsStringVisitor:\n         \"\"\"return an astroid.Assert node as string\"\"\"\n         if node.fail:\n             return f\"assert {node.test.accept(self)}, {node.fail.accept(self)}\"\n+            \"\"\"return an astroid.Assert node as string\"\"\"\n         return f\"assert {node.test.accept(self)}\"\n\n     def visit_assignname(self, node):\n@@ -158,6 +166,7 @@ class AsStringVisitor:\n         \"\"\"return an astroid.AssName node as string\"\"\"\n         return node.name\n\n+    \"\"\"return an astroid.Assign node as string\"\"\"\n     def visit_assign(self, node):\n         \"\"\"return an astroid.Assign node as string\"\"\"\n         lhs = \" = \".join(n.accept(self) for n in node.targets)\n@@ -166,6 +175,7 @@ class AsStringVisitor:\n         \"\"\"return an astroid.AugAssign node as string\"\"\"\n         return f\"{node.target.accept(self)} {node.op} {node.value.accept(self)}\"\n\n+    \"\"\"Return an astroid.AugAssign node as string\"\"\"\n     def visit_annassign(self, node):\n         \"\"\"Return an astroid.AugAssign node as string\"\"\"\n         target = node.target.accept(self)\n@@ -175,6 +185,7 @@ class AsStringVisitor:\n         if node.value is None:\n             return f\"{target}: {annotation}\"\n         return f\"{target}: {annotation} = {node.value.accept(self)}\"\n+            \"\"\"Return an astroid.AugAssign node as string\"\"\"\n\n     def visit_binop(self, node):\n         \"\"\"return an astroid.BinOp node as string\"\"\"\n@@ -183,6 +194,7 @@ class AsStringVisitor:\n         if node.op == \"**\":\n             return f\"{left}{node.op}{right}\"\n         return f\"{left} {node.op} {right}\"\n+            \"\"\"return an astroid.BinOp node as string\"\"\"\n\n     def visit_boolop(self, node):\n         \"\"\"return an astroid.BoolOp node as string\"\"\"\n@@ -191,6 +203,7 @@ class AsStringVisitor:\n         return (f\" {node.op} \").join(values)\n\n     def visit_break(self, node):\n+        \"\"\"return an astroid.Break node as string\"\"\"\n         \"\"\"return an astroid.Break node as string\"\"\"\n         return \"break\"\n\n@@ -199,6 +212,7 @@ class AsStringVisitor:\n         \"\"\"return an astroid.Call node as string\"\"\"\n         expr_str = self._precedence_parens(node, node.func)\n         args = [arg.accept(self) for arg in node.args]\n+            \"\"\"return an astroid.Call node as string\"\"\"\n         if node.keywords:\n             keywords = [kwarg.accept(self) for kwarg in node.keywords]\n         else:\n@@ -208,6 +222,7 @@ class AsStringVisitor:\n         args.extend(keywords)\n         return f\"{expr_str}({', '.join(args)})\"\n\n+    \"\"\"return an astroid.ClassDef node as string\"\"\"\n     def visit_classdef(self, node):\n         \"\"\"return an astroid.ClassDef node as string\"\"\"\n         decorate = node.decorators.accept(self) if node.decorators else \"\"\n@@ -217,6 +232,7 @@ class AsStringVisitor:\n         if node._metaclass and not node.has_metaclass_hack():\n             args.append(\"metaclass=\" + node._metaclass.accept(self))\n         args += [n.accept(self) for n in node.keywords]\n+            \"\"\"return an astroid.ClassDef node as string\"\"\"\n         args = f\"({', '.join(args)})\" if args else \"\"\n         docs = self._docs_dedent(node.doc) if node.doc else \"\"\n         return \"\\n\\n{}class {}{}:{}\\n{}\\n\".format(\n@@ -226,6 +242,7 @@ class AsStringVisitor:\n         \"\"\"return an astroid.Compare node as string\"\"\"\n         rhs_str = \" \".join(\n             f\"{op} {self._precedence_parens(node, expr, is_left=False)}\"\n+            \"\"\"return an astroid.Compare node as string\"\"\"\n             for op, expr in node.ops\n         )\n         return f\"{self._precedence_parens(node, node.left)} {rhs_str}\"\n@@ -234,6 +251,7 @@ class AsStringVisitor:\n         \"\"\"return an astroid.Comprehension node as string\"\"\"\n         ifs = \"\".join(f\" if {n.accept(self)}\" for n in node.ifs)\n         generated = f\"for {node.target.accept(self)} in {node.iter.accept(self)}{ifs}\"\n+            \"\"\"return an astroid.Comprehension node as string\"\"\"\n         return f\"{'async ' if node.is_async else ''}{generated}\"\n\n     def visit_const(self, node):\n@@ -242,6 +260,7 @@ class AsStringVisitor:\n         if node.value is Ellipsis:\n             return \"...\"\n         return repr(node.value)\n+            \"\"\"return an astroid.Const node as string\"\"\"\n\n     def visit_continue(self, node):\n         \"\"\"return an astroid.Continue node as string\"\"\"\n@@ -250,6 +269,7 @@ class AsStringVisitor:\n         \"\"\"return an astroid.Delete node as string\"\"\"\n         return f\"del {', '.join(child.accept(self) for child in node.targets)}\"\n\n+    \"\"\"return an astroid.DelAttr node as string\"\"\"\n     def visit_delattr(self, node):\n         \"\"\"return an astroid.DelAttr node as string\"\"\"\n         return self.visit_attribute(node)\n@@ -258,6 +278,7 @@ class AsStringVisitor:\n         \"\"\"return an astroid.DelName node as string\"\"\"\n         return node.name\n\n+    \"\"\"return an astroid.Decorators node as string\"\"\"\n     def visit_decorators(self, node):\n         \"\"\"return an astroid.Decorators node as string\"\"\"\n         return \"@%s\\n\" % \"\\n@\".join(item.accept(self) for item in node.nodes)\n@@ -266,6 +287,7 @@ class AsStringVisitor:\n         \"\"\"return an astroid.Dict node as string\"\"\"\n         return \"{%s}\" % \", \".join(self._visit_dict(node))\n\n+    \"\"\"return an astroid.DictUnpack node as string\"\"\"\n     def _visit_dict(self, node):\n         for key, value in node.items:\n             key ="
  },
  "pyvista__pyvista-4315": {
    "instance_id": "pyvista__pyvista-4315",
    "model_name_or_path": "codestral-latest",
    "model_patch": "--- a/pyvista/core/grid.py\n+++ b/pyvista/core/grid.py\n@@ -123,7 +123,7 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n         \"\"\"Initialize the rectilinear grid.\"\"\"\n         super().__init__()\n         if len(args) == 1:\n-            if isinstance(args[0], _vtk.vtkRectilinearGrid):\n+            if isinstance(args[0], (_vtk.vtkRectilinearGrid, np.ndarray)):\n                 if deep:\n                     self.deep_copy(args[0])\n                 else:\n@@ -133,7 +133,7 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n             elif isinstance(args[0], (str, pathlib.Path)):\n                 self._from_file(args[0], **kwargs)\n             elif isinstance(args[0], np.ndarray):\n-                self._from_arrays(args[0], None, None, check_duplicates)\n+                self._from_arrays(args[0], np.array([0]), np.array([0]), check_duplicates)\n             else:\n                 raise TypeError(f'Type ({type(args[0])}) not understood by `RectilinearGrid`')\n         elif len(args) == 3 or len(args) == 2:\n@@ -141,7 +141,7 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n             arg0_is_arr = isinstance(args[0], np.ndarray)\n             arg1_is_arr = isinstance(args[1], np.ndarray)\n             if len(args) == 3:\n-                arg2_is_arr = isinstance(args[2], np.ndarray)\n+                arg2_is_arr = isinstance(args[2], (np.ndarray, Sequence))\n             else:\n                 arg2_is_arr = False\n             if all([arg0_is_arr, arg1_is_arr, arg2_is_arr]):\n@@ -150,7 +150,7 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n             elif all([arg0_is_arr, arg1_is_arr]):\n                 self._from_arrays(args[0], args[1], None, check_duplicates)\n             else:\n-                raise TypeError(\"Arguments not understood by `RectilinearGrid`.\")\n+                raise TypeError(\"Arguments not understood by `RectilinearGrid`.\")\n     def __repr__(self):\n         \"\"\"Return the default representation.\"\"\"\n         return DataSet.__repr__(self)"
  }
}